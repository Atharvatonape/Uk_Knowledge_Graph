{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Coreference Resolution"
      ],
      "metadata": {
        "id": "pte4SIhb6XBi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################################\n",
        "# IMPORTANT NOTE:\n",
        "# In this notebook we use an experimental spaCy model\n",
        "# named \"en_coreference_web_trf\", which is not part of the\n",
        "# official library. At the current date, the official\n",
        "# documentation is unaccurate regarding the version used\n",
        "# in this tutorial. We can expect an update on the spaCy's\n",
        "# documentation: https://spacy.io/api/coref\n",
        "###########################################################"
      ],
      "metadata": {
        "id": "fvxkEGtiyKBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #1. Setup development environment"
      ],
      "metadata": {
        "id": "YuOrCyv33dD8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Update & import Python modules"
      ],
      "metadata": {
        "id": "x5nQrrW56AvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install and download spaCy related modules and dependencies\n",
        "!pip install --upgrade spacy-experimental\n",
        "!pip install https://github.com/explosion/spacy-experimental/releases/download/v0.6.0/en_coreference_web_trf-3.4.0a0-py3-none-any.whl\n",
        "\n",
        "# spaCy\n",
        "import spacy\n",
        "\n",
        "# Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "# general Python modules\n",
        "import json\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "KO2xzpIn3bx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all Python packages installed\n",
        "!pip list"
      ],
      "metadata": {
        "id": "Yyvzn5wKjKr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get access to Firebase and Drive"
      ],
      "metadata": {
        "id": "uTaktcWqxg2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# remount drive, forced if needed\n",
        "drive.mount(\"/content/gdrive/\", force_remount = True)\n",
        "print(\"Stablished access to Google Drive\")\n",
        "\n",
        "# initialize Drive path\n",
        "DRIVE_PATH = \"/content/gdrive/My Drive\""
      ],
      "metadata": {
        "id": "Cg1Wpiefq8DK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5bd42d-570d-4720-c5b5-1766aa680017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n",
            "Stablished access to Google Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve main data structures"
      ],
      "metadata": {
        "id": "xwHHVYXg-ojl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve Text Record from JSON file\n",
        "with open(DRIVE_PATH + \"/ie_course/assets/text_record.json\") as f:\n",
        "  text_rec = json.load(f)\n",
        "  print(f\"Retrieved text record\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuhu5MV3rEhZ",
        "outputId": "486c0a80-a729-4b39-c4e0-e7b2dd84dbf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved text record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #2. Resolve references\n"
      ],
      "metadata": {
        "id": "k-3AFltG6UnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create pipeline"
      ],
      "metadata": {
        "id": "ZKRy_kv3yoBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_coreference_web_trf\")"
      ],
      "metadata": {
        "id": "oHFfwJ9qymUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Coreference resolution"
      ],
      "metadata": {
        "id": "1epghUI-ez0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main_text_woc_container = []\n",
        "text = text_rec[\"texts\"]\n",
        "\n",
        "# process paragraphs individually in a stream (multi-thread)\n",
        "for doc in nlp.pipe(text, batch_size=50):\n",
        "  spans = doc.spans  # coreference\n",
        "  pprint(doc.text)\n",
        "  pprint(spans)\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMMnV7QuXx1u",
        "outputId": "f8e3d2f7-5d52-47fd-f902-4425e83192e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Chris, that’s because we have great testing, because we have the best '\n",
            " 'testing in the world. If we didn’t test, you wouldn’t be able to show that '\n",
            " 'chart. If we tested half as much, those numbers would be down. We tested-')\n",
            "{'coref_clusters_1': [we have, we have, we did, we tested, We tested-],\n",
            " 'coref_clusters_2': [Chris,, you would]}\n",
            "\n",
            "('No, no. But I don’t say… I say flames. We’ll put out the flames and we’ll '\n",
            " 'put out, in some cases, just burning embers. We also have burning embers. We '\n",
            " 'have embers and we do have flames. Florida became more flame-like, but it’s '\n",
            " 'going to be under control. And it’s not just this country. It’s many '\n",
            " 'countries. We don’t talk about it in the news. They don’t talk about Mexico, '\n",
            " 'Mexico and Brazil and still parts of Europe, which actually got hit sooner '\n",
            " 'than us, so it’s a little ahead of us in that sense. But you take a look, '\n",
            " 'why don’t they talk about Mexico, which is not helping us? And all I can say '\n",
            " 'is thank God I built most of the wall because if I didn’t have the wall up '\n",
            " 'we would have a much bigger problem with Mexico.')\n",
            "{'coref_clusters_1': [I do, I say, I can, I built, I did],\n",
            " 'coref_clusters_2': [We’ll, we’ll, We also, We have, we do, us,, us in, us?, we would],\n",
            " 'coref_clusters_3': [It’s, it in],\n",
            " 'coref_clusters_4': [Mexico,, Mexico and, Mexico,, Mexico.],\n",
            " 'coref_clusters_5': [They do, they talk],\n",
            " 'coref_clusters_6': [the wall because, the wall up]}\n",
            "\n",
            "('Yeah, I think what we’ll do… Well, we have them on a travel ban, too, Chris. '\n",
            " 'I closed them off. If you remember, I was the one that did the European '\n",
            " 'Union very early. But when you talk about mortality rates, I think it’s the '\n",
            " 'opposite. I think we have one of the lowest mortality rates in the world.')\n",
            "{'coref_clusters_1': [we’ll, we have, we have],\n",
            " 'coref_clusters_2': [I think, I closed, I was, I think, I think],\n",
            " 'coref_clusters_3': [them on, them off],\n",
            " 'coref_clusters_4': [Chris., you remember]}\n",
            "\n",
            "('Kaylee’s right here. I heard we had one of the lowest, maybe the lowest '\n",
            " 'mortality rate anywhere in the world. Do you have the numbers, please? '\n",
            " 'Because I heard we had the best mortality rate.')\n",
            "{'coref_clusters_1': [Kaylee’s, you have],\n",
            " 'coref_clusters_2': [I heard, I heard],\n",
            " 'coref_clusters_3': [we had, we had]}\n",
            "\n",
            "('Look, I take responsibility always for everything because it’s ultimately my '\n",
            " 'job to. I have to get everybody in line. Some governors have done well, some '\n",
            " 'governors have done poorly. They’re supposed to have supplies they didn’t '\n",
            " 'have, I supplied everybody. Now we have somewhat of a surge in certain areas '\n",
            " 'and other areas we’re doing great, but we have a surge in certain areas. But '\n",
            " 'you don’t hear people complaining about ventilators. We’ve got all the '\n",
            " 'ventilators we can use. We’re supplying them to other countries. We go out '\n",
            " 'into parking lots and everything, everybody gets a test. We find if we did '\n",
            " 'half the testing, with all of that being said, I’m glad we did it. This is '\n",
            " 'the right way to do it. I’m glad we did what we’re doing, but we have more '\n",
            " 'tests by far than any country in the world.')\n",
            "{'coref_clusters_1': [I take, my job, I have, I supplied, I’m, I’m],\n",
            " 'coref_clusters_2': [some governors have, They’re, they did],\n",
            " 'coref_clusters_3': [everybody in, everybody.],\n",
            " 'coref_clusters_4': [we have, we’re, we have, We’ve, we can, We’re, We go, We find, we did, we did, we did, we’re, we have],\n",
            " 'coref_clusters_5': [all the ventilators we can use., them to],\n",
            " 'coref_clusters_6': [the testing,, it., This is, it.]}\n",
            "\n",
            "('Many of those cases are young people that would heal in today. They have the '\n",
            " 'sniffles and we put it down as a test. Many of them. Don’t forget, I guess '\n",
            " 'it’s like 99.7%. People are going to get better. And in many cases, they’re '\n",
            " 'going to get better very quickly. We go out and we look, and then on the '\n",
            " 'news, look, if you go back to the news, even your wonderful competitors, '\n",
            " 'you’ll see cases are up. Cases are up. Many of those cases shouldn’t even be '\n",
            " 'cases. Cases are up because we have the best testing in the world, and we '\n",
            " 'have the most testing. No country has ever done what we’ve done in terms of '\n",
            " 'testing. We are the envy of the world. They call and they say the most '\n",
            " 'incredible job anybody’s done is our job on testing, because we’re going to '\n",
            " 'very shortly be up to 50 million tests. You look at other countries, they '\n",
            " 'don’t even do tests. They do tests if somebody walks into the hospital, '\n",
            " 'they’re sick, they’re really sick, they test them then, or they’ll test them '\n",
            " 'in a doctor’s office. But they don’t go around and have massive areas of '\n",
            " 'testing, and we do. And I’m glad we do, but it really skews the numbers.')\n",
            "{'coref_clusters_1': [young people that would heal in today., They have],\n",
            " 'coref_clusters_10': [other countries,, they do, They do, they test, they’ll, they do],\n",
            " 'coref_clusters_11': [somebody walks, they’re, they’re, them then, them in],\n",
            " 'coref_clusters_12': [I guess, I’m],\n",
            " 'coref_clusters_2': [the sniffles and, it down],\n",
            " 'coref_clusters_3': [those cases are, them.],\n",
            " 'coref_clusters_4': [People are, they’re],\n",
            " 'coref_clusters_5': [we put, We go, we look, we have, we have, we’ve, We are, our job, we’re, we do, we do],\n",
            " 'coref_clusters_6': [the news,, the news,],\n",
            " 'coref_clusters_7': [Cases are, those cases should],\n",
            " 'coref_clusters_8': [the world,, the world.],\n",
            " 'coref_clusters_9': [They call, they say]}\n",
            "\n",
            "('Excuse me. It’s all too much. It shouldn’t be one case. It came from China, '\n",
            " 'they should have never let it escape, they should have never let it out. But '\n",
            " 'it is what it is. Take a look at Europe, take a look at the numbers in '\n",
            " 'Europe. And by the way, they’re having surges.')\n",
            "{'coref_clusters_1': [It should, It came, it escape, it out, it is, it is],\n",
            " 'coref_clusters_2': [China,, they should, they should],\n",
            " 'coref_clusters_3': [Europe,, Europe.]}\n",
            "\n",
            "('No, it’s possible that they don’t test. That’s what’s possible. We find '\n",
            " 'cases, and many of those cases heal automatically. We’re finding in a way '\n",
            " 'we’re creating trouble. Certainly we’re creating trouble for the fake news '\n",
            " 'to come along and say, “Oh, we have more cases.” Look, we did something that '\n",
            " 'nobody’s ever done. Not only the ventilators where we’re supplying them all '\n",
            " 'over the world. We did a testing program, the likes of which nobody’s ever '\n",
            " 'done before.')\n",
            "{'coref_clusters_1': [don’t, That’s],\n",
            " 'coref_clusters_2': [cases,, those cases heal],\n",
            " 'coref_clusters_3': [We find, We’re, we’re, we’re, we did, we’re, We did],\n",
            " 'coref_clusters_4': [the fake news to, we have]}\n",
            "\n",
            "('I don’t know and I don’t think he knows. I don’t think anybody knows with '\n",
            " 'this. This is a very tricky deal. Everybody thought the summer it would go '\n",
            " 'away and it would come back in the fall. Well, in the summer it came, they '\n",
            " 'used to say the heat was good for it and it really knocks it out. Remember? '\n",
            " 'And then it might come back in the fall. So they got that one wrong. They '\n",
            " 'got a lot wrong. They got a lot wrong, the World Health got a tremendous '\n",
            " 'amount wrong. They basically did whatever China wanted them to. And we’ll '\n",
            " 'save now almost $500 million a year, which is nice. But the World Health got '\n",
            " 'a lot wrong.')\n",
            "{'coref_clusters_1': [I do, I do, I do],\n",
            " 'coref_clusters_2': [this., This is],\n",
            " 'coref_clusters_3': [it would, it would, it came, it and, it out, it might],\n",
            " 'coref_clusters_4': [the summer it, the summer it],\n",
            " 'coref_clusters_5': [the heat was, it really],\n",
            " 'coref_clusters_6': [the fall., the fall.],\n",
            " 'coref_clusters_7': [they used, they got, They got, They got, They basically, them to],\n",
            " 'coref_clusters_8': [the World Health got, the World Health got]}\n",
            "\n",
            "('Because we’re not. If one man from my administration doesn’t like him '\n",
            " 'because he made a few mistakes… Look, Dr. Fauci said don’t wear a mask. Dr. '\n",
            " 'Fauci told me not to ban China, it would be a big mistake. I did it over and '\n",
            " 'above his recommendation. Dr. Fauci then said, “You saved tens of thousands '\n",
            " 'of lives more than that.” He said, “You saved tens of thousands of lives.” '\n",
            " 'Dr. Fauci’s made some mistakes, but I have a very good… I spoke to him '\n",
            " 'yesterday at length. I have a very good relationship with Dr. Fauci.')\n",
            "{'coref_clusters_1': [one man from my administration does, my administration, he made, me not, I did, You saved, He said, You saved, I have, I spoke, I have],\n",
            " 'coref_clusters_2': [him because, Dr. Fauci said, Dr. Fauci told, his recommendation, Dr. Fauci then, Dr. Fauci’s, him yesterday, Dr. Fauci.],\n",
            " 'coref_clusters_3': [ban China, it would, it over, that.]}\n",
            "\n",
            "('A little bit of an alarmest. Let me just say, Dr. Fauci, at the beginning… '\n",
            " 'And again, I have a great relationship with him. I spoke to him at length '\n",
            " 'yesterday. Dr. Fauci, at the beginning, said, “This will pass. Don’t worry '\n",
            " 'about it. This will pass.” He was wrong. Dr. Fauci said, “Don’t ban China. '\n",
            " 'Don’t ban China.” I did. He then admitted that I was right.')\n",
            "{'coref_clusters_1': [me just, I have, I spoke, I did, I was],\n",
            " 'coref_clusters_2': [Dr. Fauci,, him., him at, Dr. Fauci,, He was, Dr. Fauci said, He then],\n",
            " 'coref_clusters_3': [This will, it., This will],\n",
            " 'coref_clusters_4': [China., China.]}\n",
            "\n",
            "('Then there are masks. From the first day that the CDC said that people '\n",
            " 'should wear a mask on April third, you said you weren’t going to. You wore a '\n",
            " 'mask for the first time in public at Walter Reed this weekend. Question, the '\n",
            " 'CDC says, “If everybody wore a mask for four to six weeks, we could get this '\n",
            " 'under control.” Do you regret not wearing a mask in public from the start, '\n",
            " 'and will you consider a national mandate that people need to wear masks?')\n",
            "{'coref_clusters_1': [you said, you were, You wore, you regret, you consider],\n",
            " 'coref_clusters_2': [the CDC said, the CDC says, we could]}\n",
            "\n",
            "('No, I want people to have a certain freedom and I don’t believe in that. No. '\n",
            " 'And I don’t agree with the statement that if everybody wore a mask '\n",
            " 'everything disappears. Hey, Dr. Fauci said don’t wear a mask. Our surgeon '\n",
            " 'general, terrific guy, said don’t wear a mask. Everybody was saying don’t '\n",
            " 'wear a mask. All of a sudden everybody’s got to wear a mask. And as you '\n",
            " 'know, masks cause problems, too. With that being said, I’m a believer in '\n",
            " 'masks. I think masks are good. But I leave it up to the governors. Many of '\n",
            " 'the governors are changing, they’re more mask into, they like the concept of '\n",
            " 'masks. But some of them don’t agree. I do say this, schools have to open, '\n",
            " 'young people have to go to school and there’s…')\n",
            "{'coref_clusters_1': [I want, I do, I do, I’m, I think, I leave, I do],\n",
            " 'coref_clusters_2': [have a, that.],\n",
            " 'coref_clusters_3': [everybody wore, everybody’s],\n",
            " 'coref_clusters_4': [the governors., the governors are, they’re, they like, them do]}\n",
            "\n",
            "('Have to open. Young people have to go to school and there’s problems when '\n",
            " 'you don’t go to school too. And there’s going to be a funding problem '\n",
            " 'because we’re not going to fund … When they don’t open their schools, we’re '\n",
            " 'not going to fund them. We’re not going to give them money, if they’re not '\n",
            " 'going to school, if they don’t open their schools.')\n",
            "{'coref_clusters_1': [they do, their schools, them money, they’re, they do, their schools],\n",
            " 'coref_clusters_2': [we’re, we’re, We’re],\n",
            " 'coref_clusters_3': [their schools,, them., their schools.]}\n",
            "\n",
            "('Chris, let the schools open. Did you ever see the statistics on young people '\n",
            " 'below the age of 18? The state of New Jersey had thousands of deaths. Of all '\n",
            " 'of these thousands, one person below the age of 18 in the entire state, one '\n",
            " 'person. And that was a person that had, I believe he said diabetes. One '\n",
            " 'person below the age of 18 died in the state of New Jersey during all of '\n",
            " 'this. They had a hard time and they’re doing very well now. So that’s it.')\n",
            "{'coref_clusters_1': [Chris,, you ever, I believe],\n",
            " 'coref_clusters_2': [thousands of deaths., all of these thousands,, these thousands,, all of this.],\n",
            " 'coref_clusters_3': [the age of 18?, the age of 18 in, the age of 18 died],\n",
            " 'coref_clusters_4': [The state of New Jersey had, the entire state,, the state of New Jersey during],\n",
            " 'coref_clusters_5': [one person below the age of 18 in the entire state,, one person., that was, One person below the age of 18 died],\n",
            " 'coref_clusters_6': [They had, they’re]}\n",
            "\n",
            "('So we do need some kind of immunity. You do need it, just like you need '\n",
            " 'immunity for the police. Okay? Whether they like it or not, you need '\n",
            " 'immunity for the police, but they do need a form of immunity. You don’t know '\n",
            " 'if they caught it and nobody’s ever going to be able to prove it one way or '\n",
            " 'the other. You can’t put the people out. Look, the Democrats don’t want to '\n",
            " 'do that because they’re totally captured by the lobby of lawyers. The '\n",
            " 'lawyers lobby is probably the most powerful in the country.')\n",
            "{'coref_clusters_1': [some kind of immunity., it,, it or],\n",
            " 'coref_clusters_2': [the police., they like, the police,, they do, they caught],\n",
            " 'coref_clusters_3': [it and, it one],\n",
            " 'coref_clusters_4': [put the, that because],\n",
            " 'coref_clusters_5': [the Democrats do, they’re],\n",
            " 'coref_clusters_6': [the lobby of lawyers., The lawyers lobby is]}\n",
            "\n",
            "('I explain it very simply by saying, their Democrat run cities, they’re '\n",
            " 'liberally run. They’re stupidly run. We have a forced them in Seattle to end '\n",
            " 'the chop because we were going in that following day. You probably have '\n",
            " 'heard it. We were getting ready to go in. We were all set. And when they '\n",
            " 'heard that we were going, they set their police force.')\n",
            "{'coref_clusters_1': [their Democrat run cities,, they’re, They’re],\n",
            " 'coref_clusters_2': [their Democrat, them in, they heard, they set, their police],\n",
            " 'coref_clusters_3': [We have, we were, We were, We were, we were]}\n",
            "\n",
            "('I look forward to seeing that. Meanwhile, the George Floyd murder has '\n",
            " 're-ignited the issue of racism in policing in this country. I want to give '\n",
            " 'you a couple of statistics. Nationwide, blacks are twice as likely, fewer in '\n",
            " 'absolute numbers, but in terms of per capita. Blacks are twice as likely to '\n",
            " 'be shot and killed by police as whites are. In Minneapolis over the last '\n",
            " 'five years, police use force against blacks at a rate seven times that '\n",
            " 'against whites. Can you understand why blacks would be angry at that?')\n",
            "{'coref_clusters_1': [seeing that, that.],\n",
            " 'coref_clusters_2': [I look, I want],\n",
            " 'coref_clusters_3': [use force, that?]}\n",
            "\n",
            "('Of course, I do. Of course, I do. Many whites are killed, also. You have to '\n",
            " 'say that. I mean, many, many whites are killed. I hate the sound, but this '\n",
            " 'is going on for decades. This is going on for a long time. Long before I got '\n",
            " 'here. If you look at what’s going on in Portland, those are anarchists and '\n",
            " 'we’ve taken a very tough stand. If we didn’t take a stand in Portland, we’ve '\n",
            " 'arrested many of these leaders. If we didn’t take that stand right now, you '\n",
            " 'would have a problem like … They were going to lose Portland. So let’s see '\n",
            " 'what this says here. Prosecution, sanctuary cities, incentivize illegal '\n",
            " 'alien, expand asylum, abolish immigration detention.')\n",
            "{'coref_clusters_1': [I do, I do, I mean, I hate, I got],\n",
            " 'coref_clusters_2': [are killed, that.],\n",
            " 'coref_clusters_3': [this is, This is],\n",
            " 'coref_clusters_4': [we’ve, we did, we’ve, we did],\n",
            " 'coref_clusters_5': [Portland,, Portland,, Portland.],\n",
            " 'coref_clusters_6': [a very tough stand., that stand right]}\n",
            "\n",
            "('The White House never sent us evidence, the Bernie, Biden platform calls for '\n",
            " 'defunding or abolishing police because there is none. It calls for increased '\n",
            " 'funding for police departments that meet certain standards. Joe Biden has '\n",
            " 'called for redirecting some police funding for related programs like mental '\n",
            " 'health counseling.')\n",
            "{'coref_clusters_1': [the Bernie, Biden platform calls, It calls],\n",
            " 'coref_clusters_2': [Biden platform, Joe Biden has]}\n",
            "\n",
            "('I just look at school. I watch, I read. Look at the stuff. Now they want to '\n",
            " 'change, 1492 Columbus discovered America. We grew up, you grew up, we all '\n",
            " 'did. That’s what we learned. Now, they want to make it the 1619 Project. '\n",
            " 'Where did that come from? What does it represent? I don’t even know.')\n",
            "{'coref_clusters_1': [I just, I watch, I read, I do],\n",
            " 'coref_clusters_2': [We grew, we all did, we learned],\n",
            " 'coref_clusters_3': [discovered America, That’s],\n",
            " 'coref_clusters_4': [they want, they want],\n",
            " 'coref_clusters_5': [that come, it represent]}\n",
            "\n",
            "('We haven’t had… Excuse me. You heard me yesterday. We’re signing a '\n",
            " 'healthcare plan within two weeks. A full and complete health care plan that '\n",
            " 'the Supreme Court decision on DACA gave me the right to do. So we’re going '\n",
            " 'to solve… We’re going to sign an immigration plan, a healthcare plan and '\n",
            " 'various other plans. And nobody will have done what I’m doing in the next '\n",
            " 'four weeks. The Supreme Court gave the President of the United States powers '\n",
            " 'that nobody thought the president had, by approving, by doing what they did, '\n",
            " 'their decision on DACA. And DACA is going to be taken care of also. But '\n",
            " 'we’re getting rid of it because we’re going to replace it with something '\n",
            " 'much better. But we got rid of already, which was most of Obamacare, the '\n",
            " 'individual mandate. And that I’ve already won on. And we won also on the '\n",
            " 'Supreme Court. But the decision by the Supreme Court on DACA allows me to do '\n",
            " 'things on immigration, on healthcare, on other things that we’ve never done '\n",
            " 'before. And you’re going to find it to be a very exciting two weeks.')\n",
            "{'coref_clusters_1': [me., me yesterday, me the, I’m, I’ve, me to],\n",
            " 'coref_clusters_2': [a healthcare plan within two weeks., A full and complete health care plan that the Supreme Court decision on DACA gave me the right to do., an immigration plan, a healthcare plan and various other plans.],\n",
            " 'coref_clusters_3': [We’re, we’re, We’re, we’re, we’re, we got, we won, we’ve],\n",
            " 'coref_clusters_4': [Supreme Court decision, The Supreme Court gave, they did, their decision, the Supreme Court., the Supreme Court on],\n",
            " 'coref_clusters_5': [the President of the United States powers, the president had],\n",
            " 'coref_clusters_6': [the Supreme Court decision on DACA gave, their decision on DACA., the decision by the Supreme Court on DACA allows],\n",
            " 'coref_clusters_7': [DACA gave, DACA., DACA is, it because, it with, DACA allows]}\n",
            "\n",
            "('And let me thank Patrisse Cullors. Patrisse, as you all know, is one of the '\n",
            " 'co-founders of Black Lives Matter. And she has in her work, helped change '\n",
            " 'the course of American history. Patrice, thank you very much for what you '\n",
            " 'are doing. And let me take Marisa Franco for her beautiful remarks. Marisa '\n",
            " 'is the executive director at Mijente. I know you are going to want to listen '\n",
            " 'to some music in a few minutes, right? So I have decided to a limit my '\n",
            " 'remarks to three hours. All right. If you insist, we will make it four '\n",
            " 'hours. I think we can get the message out fairly shortly and that is, we are '\n",
            " 'going to defeat the most dangerous President in modern American history. '\n",
            " 'With your help on Tuesday, we are going to win the Democratic primary here '\n",
            " 'in California. With your help, we are going to win the democratic '\n",
            " 'nomination. And with your help, we are going to defeat the most dangerous '\n",
            " 'President in the modern history of America.')\n",
            "{'coref_clusters_1': [Patrisse Cullors., Patrisse,, she has, her work, Patrice,, you very, you are, your help, your help, your help],\n",
            " 'coref_clusters_2': [me thank, me take, I know, I have, my remarks, I think],\n",
            " 'coref_clusters_3': [Marisa Franco for, her beautiful, Marisa is],\n",
            " 'coref_clusters_4': [her beautiful remarks., my remarks to, it four],\n",
            " 'coref_clusters_5': [you are, you insist],\n",
            " 'coref_clusters_6': [we will, we can, we are, we are, we are, we are],\n",
            " 'coref_clusters_7': [the message out, that is],\n",
            " 'coref_clusters_8': [the most dangerous President in modern American history., the most dangerous President in the modern history of America.],\n",
            " 'coref_clusters_9': [modern American history., the modern history of America.]}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## #3. Utils (optional)"
      ],
      "metadata": {
        "id": "5meI_LYkeCCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple coreference resolution example"
      ],
      "metadata": {
        "id": "BbCRZ0P_eeNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"John Smith called from New York. He says it's raining in the city.\")\n",
        "print(doc.spans)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKaeCLVPWOWd",
        "outputId": "f8637595-194d-47b4-f1f3-a540a795681f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'coref_clusters_1': [John Smith called, He says], 'coref_clusters_2': [New York., the city.]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analize the pipeline"
      ],
      "metadata": {
        "id": "Xw7XrwWmd6Rp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# see pipeline components\n",
        "print(nlp.pipe_names)\n",
        "\n",
        "# analize pipeline\n",
        "pprint(nlp.analyze_pipes(pretty=True))"
      ],
      "metadata": {
        "id": "8zL3NpHbmKFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc07117f-d15c-4d06-9a1c-f8cb62363e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['sentencizer', 'transformer', 'coref', 'span_resolver', 'span_cleaner']\n",
            "\u001b[1m\n",
            "============================= Pipeline Overview =============================\u001b[0m\n",
            "\n",
            "#   Component       Assigns               Requires    Scores          Retokenizes\n",
            "-   -------------   -------------------   ---------   -------------   -----------\n",
            "0   sentencizer     token.is_sent_start               sents_f         False      \n",
            "                    doc.sents                         sents_p                    \n",
            "                                                      sents_r                    \n",
            "                                                                                 \n",
            "1   transformer     doc._.trf_data                                    False      \n",
            "                                                                                 \n",
            "2   coref           doc.spans             doc.spans   coref_f         False      \n",
            "                                                      coref_p                    \n",
            "                                                      coref_r                    \n",
            "                                                                                 \n",
            "3   span_resolver   doc.spans             doc.spans   span_accuracy   False      \n",
            "                                                                                 \n",
            "4   span_cleaner    doc.spans                                         False      \n",
            "\n",
            "\u001b[1m\n",
            "================================ Problems (1) ================================\u001b[0m\n",
            "\u001b[38;5;3m⚠ 'coref' requirements not met: doc.spans\u001b[0m\n",
            "{'attrs': {'doc._.trf_data': {'assigns': ['transformer'], 'requires': []},\n",
            "           'doc.sents': {'assigns': ['sentencizer'], 'requires': []},\n",
            "           'doc.spans': {'assigns': ['coref', 'span_resolver', 'span_cleaner'],\n",
            "                         'requires': ['coref', 'span_resolver']},\n",
            "           'token.is_sent_start': {'assigns': ['sentencizer'], 'requires': []}},\n",
            " 'problems': {'coref': ['doc.spans'],\n",
            "              'sentencizer': [],\n",
            "              'span_cleaner': [],\n",
            "              'span_resolver': [],\n",
            "              'transformer': []},\n",
            " 'summary': {'coref': {'assigns': ['doc.spans'],\n",
            "                       'requires': ['doc.spans'],\n",
            "                       'retokenizes': False,\n",
            "                       'scores': ['coref_f', 'coref_p', 'coref_r']},\n",
            "             'sentencizer': {'assigns': ['token.is_sent_start', 'doc.sents'],\n",
            "                             'requires': [],\n",
            "                             'retokenizes': False,\n",
            "                             'scores': ['sents_f', 'sents_p', 'sents_r']},\n",
            "             'span_cleaner': {'assigns': ['doc.spans'],\n",
            "                              'requires': [],\n",
            "                              'retokenizes': False,\n",
            "                              'scores': []},\n",
            "             'span_resolver': {'assigns': ['doc.spans'],\n",
            "                               'requires': ['doc.spans'],\n",
            "                               'retokenizes': False,\n",
            "                               'scores': ['span_accuracy']},\n",
            "             'transformer': {'assigns': ['doc._.trf_data'],\n",
            "                             'requires': [],\n",
            "                             'retokenizes': False,\n",
            "                             'scores': []}}}\n"
          ]
        }
      ]
    }
  ]
}